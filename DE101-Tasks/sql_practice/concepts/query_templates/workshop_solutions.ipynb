{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b014e2-b165-4c62-91cc-0e69de034371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the extension\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b97ff90-57f2-4e0c-ac47-69e7be6e2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DuckDB\n",
    "# NOTE: ONLY 1 NOTEBOOK CAN BE CONNECTED TO DUCKDB AT ANY TIME\n",
    "%sql duckdb:///../../tpch.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7af1b5d-eccc-485b-a72c-6c8535adfa43",
   "metadata": {},
   "source": [
    "## [Exercise] \n",
    "\n",
    "Write a query to remove duplicates from the clickstream data (created as CTE below)\n",
    "\n",
    "**Time limit during live workshop: 5 min**\n",
    "\n",
    "**Hint:**\n",
    "  1. Think about how you can use `row_number` as shown above to remove duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4c6ca9-b151-43fc-8fa4-674e737da3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH clickstream AS (\n",
    "    SELECT\n",
    "        1 AS user_id, '2024-07-01 10:00:00' AS click_time UNION ALL\n",
    "    SELECT\n",
    "        1 AS user_id, '2024-07-01 10:05:00' AS click_time UNION ALL\n",
    "    SELECT\n",
    "        1 AS user_id, '2024-07-01 10:10:00' AS click_time UNION ALL\n",
    "    SELECT\n",
    "        1 AS user_id, '2024-07-01 10:10:00' AS click_time UNION ALL\n",
    "    SELECT\n",
    "        1 AS user_id, '2024-07-01 10:10:00' AS click_time UNION ALL\n",
    "    SELECT\n",
    "        1 AS user_id, '2024-07-01 10:10:00' AS click_time UNION ALL\n",
    "    SELECT\n",
    "        2 AS user_id, '2024-07-01 10:15:00' AS click_time UNION ALL\n",
    "    SELECT\n",
    "        2 AS user_id, '2024-07-01 10:20:00' AS click_time UNION ALL\n",
    "    SELECT\n",
    "        2 AS user_id, '2024-07-01 10:20:00' AS click_time UNION ALL\n",
    "    SELECT\n",
    "        2 AS user_id, '2024-07-01 10:20:00' AS click_time UNION ALL\n",
    "    SELECT\n",
    "        2 AS user_id, '2024-07-01 10:20:00' AS click_time UNION ALL\n",
    "    SELECT\n",
    "        2 AS user_id, '2024-07-01 10:25:00' AS click_time\n",
    "),\n",
    "ranked_clicks AS (\n",
    "    SELECT\n",
    "        user_id,\n",
    "        click_time,\n",
    "        ROW_NUMBER() OVER (PARTITION BY user_id, click_time) AS click_rank\n",
    "    FROM\n",
    "        clickstream\n",
    ")\n",
    "SELECT\n",
    "    user_id,\n",
    "    click_time,\n",
    "    click_rank\n",
    "FROM\n",
    "    ranked_clicks\n",
    "WHERE\n",
    "    click_rank = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644a86f8-6442-4e38-a263-29a6cbf81fd3",
   "metadata": {},
   "source": [
    "\n",
    "## [Exercise] \n",
    "\n",
    "Write a query to pivot orders data by orderpriority and show average total price grouped by year\n",
    "    \n",
    "**Time limit during live workshop: 5 min**\n",
    "\n",
    "**Hint**: \n",
    "    1. Use `strftime(o_orderdate, '%Y') AS order_year` to get order_year.\n",
    "\n",
    "`orders` table schema: ![Orders](../../images/orders.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb18417-fc57-4016-a3b2-60eb9d42147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT strftime(o_orderdate, '%Y') AS order_year,\n",
    "       ROUND(AVG(CASE\n",
    "                     WHEN o_orderpriority = '1-URGENT' THEN o_totalprice\n",
    "                     ELSE NULL\n",
    "                 END), 2) AS urgent_order_avg_price,\n",
    "       ROUND(AVG(CASE\n",
    "                     WHEN o_orderpriority = '2-HIGH' THEN o_totalprice\n",
    "                     ELSE NULL\n",
    "                 END), 2) AS high_order_avg_price,\n",
    "       ROUND(AVG(CASE\n",
    "                     WHEN o_orderpriority = '3-MEDIUM' THEN o_totalprice\n",
    "                     ELSE NULL\n",
    "                 END), 2) AS medium_order_avg_price,\n",
    "       ROUND(AVG(CASE\n",
    "                     WHEN o_orderpriority = '4-NOT SPECIFIED' THEN o_totalprice\n",
    "                     ELSE NULL\n",
    "                 END), 2) AS not_specified_order_avg_price,\n",
    "       ROUND(AVG(CASE\n",
    "                     WHEN o_orderpriority = '5-LOW' THEN o_totalprice\n",
    "                     ELSE NULL\n",
    "                 END), 2) AS low_order_avg_price\n",
    "FROM orders\n",
    "GROUP BY strftime(o_orderdate, '%Y');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4573366-9406-4ff4-af6c-89adda0db968",
   "metadata": {},
   "source": [
    "## [Exercise]\n",
    "\n",
    "* Scenario: You are designing a data set for a dashboard. The dashboard should be able to show metrics at day, week, month, and year levels (assume these are drop-downs on the dashboard).\n",
    "\n",
    "* Assume that you, the data engineer assigned to building the table necessary for the dashboard.\n",
    "\n",
    "* Question 1: What clarifying questions would you ask the dashboard team?\n",
    "\n",
    "* Question 2: How would you design the table to be used by the dashboard software? What are the considerations you need to be mindful of?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708e051b-199c-4e56-bd17-67d8974221ac",
   "metadata": {},
   "source": [
    "### Question 1: What clarifying questions would you ask the dashboard team?\n",
    "\n",
    "1. **Metrics Scope:**\n",
    "   - What specific metrics are required to be displayed on the dashboard (e.g., sales, revenue, number of orders, user sign-ups, etc.)?\n",
    "\n",
    "2. **Filtering and Segmentation:**\n",
    "   - Will the dashboard require filtering or segmentation based on dimensions like region, product category, user demographics, etc.?\n",
    "   - Are there any drill-down capabilities (e.g., from year to quarter to month) that need to be supported?\n",
    "\n",
    "3. **Performance Requirements:**\n",
    "   - What are the performance expectations for the dashboard (e.g., should the data load in real-time, or is some delay acceptable)?\n",
    "   - How often will the data be refreshed (real-time, hourly, daily, etc.)?\n",
    "\n",
    "4. **Historical Data:**\n",
    "   - How much historical data needs to be maintained and made available on the dashboard?\n",
    "\n",
    "5. **Visualization Requirements:**\n",
    "   - Are there any specific visualization requirements or preferences that might affect how the data is structured (e.g., time series charts, heatmaps, etc.)?\n",
    "\n",
    "6. **Data Volume and Scalability:**\n",
    "   - What is the expected data volume, and do you foresee this data volume growing significantly over time?\n",
    "   - Should the design account for scalability to handle increasing data volume or additional metrics in the future?\n",
    "\n",
    "### Question 2: How would you design the table to be used by the dashboard software? What are the considerations you need to be mindful of?\n",
    "\n",
    "#### Table Design:\n",
    "\n",
    "1. **Fact Table Structure:**\n",
    "   - **Granularity:** Design a fact table at the finest level of granularity required, such as daily transactions or events. This allows for flexible aggregation at higher levels (weekly, monthly, yearly) as needed.\n",
    "   - **Date Dimension:** Include a `date_key` foreign key that links to a date dimension table. This date dimension should include columns for the day, week, month, quarter, and year to facilitate easy aggregation.\n",
    "   - **Metrics Columns:** Include columns for each metric required by the dashboard, such as `total_sales`, `total_orders`, `total_revenue`, etc.\n",
    "\n",
    "2. **Date Dimension Table:**\n",
    "   - **Date Hierarchy:** Design the date dimension table to include columns like `date`, `day_of_week`, `week_of_year`, `month`, `quarter`, and `year`.\n",
    "   - **Fiscal Calendar:** If the organization uses a fiscal calendar, include fiscal year, fiscal quarter, and fiscal month columns.\n",
    "   - **Special Dates:** Include flags or indicators for holidays, weekends, or other significant dates that might affect metrics.\n",
    "\n",
    "3. **Pre-Aggregation and Summary Tables:**\n",
    "   - **Aggregated Tables:** Consider creating pre-aggregated summary tables at the weekly, monthly, and yearly levels to improve query performance on the dashboard. These tables can be refreshed periodically.\n",
    "   - **Partitioning:** Partition the data by date, week, or month to optimize query performance and manage large data volumes efficiently.\n",
    "\n",
    "4. **Partitions and Optimization:**\n",
    "   - **Partitions:** Create appropriate partitions on commonly queried columns, such as `date_key`, `order_id`, and `customer_id`, to improve query performance.\n",
    "   - **Materialized Views:** If the database supports materialized views, consider using them to store pre-computed aggregates that are frequently accessed.\n",
    "\n",
    "5. **Handling Historical Data:**\n",
    "   - **Data Retention:** Implement a data retention strategy that balances performance and storage costs. For example, keep detailed daily data for the most recent years and aggregate older data.\n",
    "   - **Archiving:** Archive historical data that is no longer required for the dashboard but may need to be retained for compliance or historical analysis.\n",
    "\n",
    "6. **Data Quality and Validation:**\n",
    "   - **Data Integrity:** Ensure referential integrity between the fact and dimension tables.\n",
    "   - **Validation Checks:** Implement data validation checks to ensure accuracy, such as verifying that totals match expected values and that all dates are populated in the date dimension.\n",
    "\n",
    "#### Considerations:\n",
    "\n",
    "- **Performance:** The design should ensure that queries run quickly, even as data volume grows. Pre-aggregated tables, partitioning, and indexing are critical considerations.\n",
    "- **Scalability:** The design should be scalable to handle increasing data volumes and the addition of new metrics or dimensions in the future.\n",
    "- **Flexibility:** The table design should be flexible enough to support different levels of granularity and the ability to drill down from year to quarter to month to day.\n",
    "- **Data Refresh:** Ensure that the data refresh process is efficient and that the dashboard displays up-to-date information based on the refresh frequency.\n",
    "- **User Experience:** Design the data structure to support a smooth and responsive user experience on the dashboard, with minimal delays when switching between different views (day, week, month, year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2cfa55-8d68-48b0-8356-33ad2e097613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
